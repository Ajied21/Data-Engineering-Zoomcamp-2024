{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\G2 Academy\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\pyspark\\\\__init__.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('data-engineering-zoomcamp-batch') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType ([\n",
    "         StructField(\"dispatching_base_num\",StringType(), True),\n",
    "         StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "         StructField(\"dropoff_datetime\", TimestampType(), True),\n",
    "         StructField(\"PUlocationID\", IntegerType(), True),\n",
    "         StructField(\"DOlocationID\", IntegerType(), True),\n",
    "         StructField(\"SR_Flag\", IntegerType(), True),\n",
    "         StructField(\"Affiliated_base_number\", StringType(), True),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|pickup_datetime    |dropoff_datetime   |PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|B00009              |2019-10-01 00:23:00|2019-10-01 00:35:00|264         |264         |NULL   |B00009                |\n",
      "|B00013              |2019-10-01 00:11:29|2019-10-01 00:13:22|264         |264         |NULL   |B00013                |\n",
      "|B00014              |2019-10-01 00:11:43|2019-10-01 00:37:20|264         |264         |NULL   |B00014                |\n",
      "|B00014              |2019-10-01 00:56:29|2019-10-01 00:57:47|264         |264         |NULL   |B00014                |\n",
      "|B00014              |2019-10-01 00:23:09|2019-10-01 00:28:27|264         |264         |NULL   |B00014                |\n",
      "|B00021              |2019-10-01 00:00:48|2019-10-01 00:07:12|129         |129         |NULL   |B00021                |\n",
      "|B00021              |2019-10-01 00:47:23|2019-10-01 00:53:25|57          |57          |NULL   |B00021                |\n",
      "|B00021              |2019-10-01 00:10:06|2019-10-01 00:19:50|173         |173         |NULL   |B00021                |\n",
      "|B00021              |2019-10-01 00:51:37|2019-10-01 01:06:14|226         |226         |NULL   |B00021                |\n",
      "|B00021              |2019-10-01 00:28:23|2019-10-01 00:34:33|56          |56          |NULL   |B00021                |\n",
      "|B00021              |2019-10-01 00:31:17|2019-10-01 00:51:52|82          |82          |NULL   |B00021                |\n",
      "|B00037              |2019-10-01 00:07:41|2019-10-01 00:15:23|264         |71          |NULL   |B00037                |\n",
      "|B00037              |2019-10-01 00:13:38|2019-10-01 00:25:51|264         |39          |NULL   |B00037                |\n",
      "|B00037              |2019-10-01 00:42:40|2019-10-01 00:53:47|264         |188         |NULL   |B00037                |\n",
      "|B00037              |2019-10-01 00:58:46|2019-10-01 01:10:11|264         |91          |NULL   |B00037                |\n",
      "|B00037              |2019-10-01 00:09:49|2019-10-01 00:14:37|264         |71          |NULL   |B00037                |\n",
      "|B00037              |2019-10-01 00:22:35|2019-10-01 00:36:53|264         |35          |NULL   |B00037                |\n",
      "|B00037              |2019-10-01 00:54:27|2019-10-01 01:03:37|264         |61          |NULL   |B00037                |\n",
      "|B00037              |2019-10-01 00:08:12|2019-10-01 00:28:47|264         |198         |NULL   |B00037                |\n",
      "|B00053              |2019-10-01 00:05:24|2019-10-01 00:53:03|264         |264         |NULL   |#N/A                  |\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:/Users/G2 Academy/OneDrive/Desktop/data-engineering-zoomcamp-2024/05-batch/code_spark/source/fhv_tripdata_2019-10.csv.gz\"\n",
    "\n",
    "df = spark.read.csv(file_path, header=True, schema=schema)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as data:\n",
    "    \n",
    "    df.write.parquet(data, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(file_path) \\\n",
    "          .createOrReplaceTempView(\"fhv_tripdata_2019_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   NULL|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   NULL|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   NULL|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   NULL|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   NULL|       B00021         |\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   NULL|       B00021         |\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   NULL|                B00037|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   NULL|                B00037|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   NULL|                  #N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * \\\n",
    "          FROM fhv_tripdata_2019_10\") \\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|total_taxi_trips_on_the_15th_of_October|\n",
      "+---------------------------------------+\n",
      "|                                  62610|\n",
      "+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) as total_taxi_trips_on_the_15th_of_October \\\n",
    "          FROM fhv_tripdata_2019_10 \\\n",
    "          WHERE DATE(pickup_datetime) = '2019-10-15' \") \\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------------+\n",
      "|dispatching_base_num|the_longest_trip_in_hours|\n",
      "+--------------------+-------------------------+\n",
      "|              B02832|                   631152|\n",
      "|              B02416|                    87672|\n",
      "|     B00746         |                    70128|\n",
      "|              B02921|                     8794|\n",
      "|              B03110|                     8784|\n",
      "|              B03080|                     1464|\n",
      "|     B03084         |                     1056|\n",
      "|              B01452|                      793|\n",
      "|              B00972|                      792|\n",
      "|              B02418|                      745|\n",
      "|              B01455|                      744|\n",
      "|              B02732|                      604|\n",
      "|              B02532|                      469|\n",
      "|              B02546|                      432|\n",
      "|              B01985|                      398|\n",
      "|              B03184|                      355|\n",
      "|              B03107|                      266|\n",
      "|              B02037|                      240|\n",
      "|              B00272|                      168|\n",
      "|              B02067|                      167|\n",
      "+--------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT dispatching_base_num, \\\n",
    "          MAX(TIMESTAMPDIFF(HOUR, pickup_datetime, dropoff_datetime)) as the_longest_trip_in_hours \\\n",
    "          FROM fhv_tripdata_2019_10 \\\n",
    "          GROUP BY dispatching_base_num \\\n",
    "          ORDER BY the_longest_trip_in_hours DESC\") \\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_zone = StructType ([\n",
    "              StructField(\"LocationID\",IntegerType(), True),\n",
    "              StructField(\"Borough\", StringType(), True),\n",
    "              StructField(\"Zone\", StringType(), True),\n",
    "              StructField(\"service_zone\", StringType(), True),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n",
      "+----------+-------------+-----------------------+------------+\n",
      "|LocationID|Borough      |Zone                   |service_zone|\n",
      "+----------+-------------+-----------------------+------------+\n",
      "|1         |EWR          |Newark Airport         |EWR         |\n",
      "|2         |Queens       |Jamaica Bay            |Boro Zone   |\n",
      "|3         |Bronx        |Allerton/Pelham Gardens|Boro Zone   |\n",
      "|4         |Manhattan    |Alphabet City          |Yellow Zone |\n",
      "|5         |Staten Island|Arden Heights          |Boro Zone   |\n",
      "|6         |Staten Island|Arrochar/Fort Wadsworth|Boro Zone   |\n",
      "|7         |Queens       |Astoria                |Boro Zone   |\n",
      "|8         |Queens       |Astoria Park           |Boro Zone   |\n",
      "|9         |Queens       |Auburndale             |Boro Zone   |\n",
      "|10        |Queens       |Baisley Park           |Boro Zone   |\n",
      "|11        |Brooklyn     |Bath Beach             |Boro Zone   |\n",
      "|12        |Manhattan    |Battery Park           |Yellow Zone |\n",
      "|13        |Manhattan    |Battery Park City      |Yellow Zone |\n",
      "|14        |Brooklyn     |Bay Ridge              |Boro Zone   |\n",
      "|15        |Queens       |Bay Terrace/Fort Totten|Boro Zone   |\n",
      "|16        |Queens       |Bayside                |Boro Zone   |\n",
      "|17        |Brooklyn     |Bedford                |Boro Zone   |\n",
      "|18        |Bronx        |Bedford Park           |Boro Zone   |\n",
      "|19        |Queens       |Bellerose              |Boro Zone   |\n",
      "|20        |Bronx        |Belmont                |Boro Zone   |\n",
      "+----------+-------------+-----------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_zone_path = \"C:/Users/G2 Academy/OneDrive/Desktop/data-engineering-zoomcamp-2024/05-batch/code_spark/source/taxi_zone_lookup.csv\"\n",
    "\n",
    "df_zone = spark.read.csv(file_zone_path, header=True, schema=schema_zone)\n",
    "\n",
    "df_zone.printSchema()\n",
    "df_zone.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(file_zone_path) \\\n",
    "          .createOrReplaceTempView(\"taxi_zone_lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * \\\n",
    "          FROM taxi_zone_lookup\") \\\n",
    "     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|                Zone|total_pickup_location|\n",
      "+--------------------+---------------------+\n",
      "|         Jamaica Bay|                    1|\n",
      "|Governor's Island...|                    2|\n",
      "| Green-Wood Cemetery|                    5|\n",
      "|       Broad Channel|                    8|\n",
      "|     Highbridge Park|                   14|\n",
      "|        Battery Park|                   15|\n",
      "|Saint Michaels Ce...|                   23|\n",
      "|Breezy Point/Fort...|                   25|\n",
      "|Marine Park/Floyd...|                   26|\n",
      "|        Astoria Park|                   29|\n",
      "|    Inwood Hill Park|                   39|\n",
      "|       Willets Point|                   47|\n",
      "|Forest Park/Highl...|                   53|\n",
      "|  Brooklyn Navy Yard|                   57|\n",
      "|        Crotona Park|                   62|\n",
      "|        Country Club|                   77|\n",
      "|     Freshkills Park|                   89|\n",
      "|       Prospect Park|                   98|\n",
      "|     Columbia Street|                  105|\n",
      "|  South Williamsburg|                  110|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT zones.Zone, COUNT(trips.PUlocationID) as total_pickup_location \\\n",
    "          FROM fhv_tripdata_2019_10 as trips \\\n",
    "          INNER JOIN taxi_zone_lookup as zones \\\n",
    "          ON trips.PUlocationID = zones.LocationID \\\n",
    "          GROUP BY zones.Zone \\\n",
    "          ORDER BY total_pickup_location ASC \") \\\n",
    "     .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
